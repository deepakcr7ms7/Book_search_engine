{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115acd50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 133>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    130\u001B[0m     top_recs\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop_recs.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 134\u001B[0m     title\u001B[38;5;241m=\u001B[39m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbooks_titles.json\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;66;03m#to make search easier we conver titles into TF-IDF score\u001B[39;00m\n\u001B[0;32m    140\u001B[0m     vectorizor\u001B[38;5;241m=\u001B[39mTfidfVectorizer()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:207\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\json\\_json.py:612\u001B[0m, in \u001B[0;36mread_json\u001B[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001B[0m\n\u001B[0;32m    609\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m json_reader\n\u001B[0;32m    611\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m json_reader:\n\u001B[1;32m--> 612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjson_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\json\\_json.py:746\u001B[0m, in \u001B[0;36mJsonReader.read\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    744\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_object_parser(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_lines(data_lines))\n\u001B[0;32m    745\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 746\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_object_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\json\\_json.py:768\u001B[0m, in \u001B[0;36mJsonReader._get_object_parser\u001B[1;34m(self, json)\u001B[0m\n\u001B[0;32m    766\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    767\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframe\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 768\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[43mFrameParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    770\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseries\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    771\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, \u001B[38;5;28mbool\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\json\\_json.py:880\u001B[0m, in \u001B[0;36mParser.parse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    878\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_numpy()\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 880\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_no_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    883\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\json\\_json.py:1133\u001B[0m, in \u001B[0;36mFrameParser._parse_no_numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1129\u001B[0m orient \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morient\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m orient \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj \u001B[38;5;241m=\u001B[39m DataFrame(\n\u001B[1;32m-> 1133\u001B[0m         \u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecise_float\u001B[49m\u001B[43m)\u001B[49m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1134\u001B[0m     )\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m orient \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1136\u001B[0m     decoded \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;28mstr\u001B[39m(k): v\n\u001B[0;32m   1138\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m loads(json, precise_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecise_float)\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1139\u001B[0m     }\n",
      "\u001B[1;31mValueError\u001B[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mark_click(val):\n",
    "    return '<img src=\"{}\" width=50></img>'.format(val)\n",
    "\n",
    "\n",
    "\n",
    "def search_query(query,vectorizor):\n",
    "    #process the qurey as we did with ours titles\n",
    "    processed_query=re.sub('[^a-zA-Z0-9]','',query.lower())\n",
    "    #get the TFidf score\n",
    "    score=vectorizor.transform([processed_query])\n",
    "    #search-using cosine transfrom\n",
    "\n",
    "    similarity=cosine_similarity(score,tfidf).flatten()\n",
    "    # similarity is cosine score of all tiltes and current query\n",
    "\n",
    "    #now to get the 3 highest values of cosine similarity\n",
    "\n",
    "    indices=np.argpartition(similarity,-3)[-3:]\n",
    "\n",
    "    #result we will get the actual titles\n",
    "\n",
    "    result=title.iloc[indices]\n",
    "    #print(result)\n",
    "    result=result.sort_values('ratings',ascending=False)\n",
    "    \n",
    "    #use result of collbrative filtering \n",
    "    top_recs=pd.read_csv('top_recs.csv')\n",
    "    top_recs.drop(['mod_title', 'mean','count','adjusted_count','score'], axis=1, inplace=True)\n",
    "    result.drop(['mod_title'], axis=1, inplace=True)\n",
    "    result = pd.concat([result,top_recs])\n",
    "    result.drop(columns=result.columns[-1], axis=1, inplace=True)\n",
    "    result.reset_index(drop=True,inplace=True)\n",
    "    return result.head(10).style.format({'cover_image':mark_click})\n",
    "\n",
    "\n",
    "def collabrative_filtering(id):\n",
    "    #print('cf')\n",
    "    id=int(id)\n",
    "    r = pd.read_csv( 'goodbooks/ratings.csv' )\n",
    "    \n",
    "    \n",
    "    #Finding out the books liked by the user\n",
    "    test=r.loc[pd.to_numeric(r['rating'])>3]\n",
    "    liked_books=test.groupby('user_id')['book_id'].apply(set)#.reset_index(name=\"liked\")\n",
    "    my_books=test.groupby('user_id')\n",
    "    books_titles = pd.read_json(\"books_titles.json\")\n",
    "    liked_book_id=liked_books[id]\n",
    "    books_titles['book_id']=books_titles['book_id'].astype(str)\n",
    "    my_books=books_titles[pd.to_numeric(books_titles['book_id']).isin(liked_book_id)].copy()\n",
    "    my_books[\"book_id\"] = my_books[\"book_id\"].astype(str)\n",
    "    user=[id]*len(my_books)\n",
    "    my_books.insert(0,'user_id',user)\n",
    "    book_set = set(my_books[\"book_id\"])\n",
    "    \n",
    "    #Finding out the people who also like same books as the user\n",
    "    overlap_users = {}\n",
    "\n",
    "    with open( 'goodbooks/ratings.csv', 'r') as f:\n",
    "        csvReader = csv.DictReader(f)\n",
    "\n",
    "        # convert each csv row into python dict\n",
    "        book_titles=[]\n",
    "        for l in csvReader:\n",
    "            if l['book_id'] in book_set:\n",
    "                if l['user_id'] not in overlap_users:\n",
    "                    overlap_users[l['user_id']] = 1\n",
    "                else:\n",
    "                    overlap_users[l['user_id']] += 1\n",
    "    filtered_overlap_users = set([k for k in overlap_users if overlap_users[k] > my_books.shape[0]/5])\n",
    "    interactions_list = []\n",
    "\n",
    "    with open('goodbooks/ratings.csv', 'r') as f:\n",
    "\n",
    "        csvReader = csv.DictReader(f)\n",
    "\n",
    "        # convert each csv row into python dict\n",
    "        for l in csvReader:\n",
    "            if l['user_id'] in filtered_overlap_users:\n",
    "\n",
    "                interactions_list.append([l['user_id'],l['book_id'],l['rating']])\n",
    "                \n",
    "    interactions = pd.DataFrame(interactions_list, columns=[\"user_id\", \"book_id\", \"ratings\"])\n",
    "    interactions = pd.concat([my_books[['user_id','book_id', \"ratings\"]], interactions])\n",
    "    interactions[\"book_id\"] = interactions[\"book_id\"].astype(str)\n",
    "    interactions[\"user_id\"] = interactions[\"user_id\"].astype(str)\n",
    "    interactions[\"ratings\"] = pd.to_numeric(interactions[\"ratings\"])\n",
    "    interactions[\"user_index\"] = interactions[\"user_id\"].astype(\"category\").cat.codes\n",
    "    interactions[\"book_index\"] = interactions[\"book_id\"].astype(\"category\").cat.codes\n",
    " \n",
    "\n",
    "    ratings_mat_coo = coo_matrix((interactions[\"ratings\"], (interactions[\"user_index\"], interactions[\"book_index\"])))\n",
    "    ratings_mat = ratings_mat_coo.tocsr()\n",
    "    interactions[interactions[\"user_id\"] == str(id)]\n",
    "    my_index = 0\n",
    "    similarity = cosine_similarity(ratings_mat[my_index,:], ratings_mat).flatten()\n",
    "    indices = np.argpartition(similarity, -15)[-15:]\n",
    "    similar_users = interactions[interactions[\"user_index\"].isin(indices)].copy()\n",
    "    similar_users = similar_users[similar_users[\"user_id\"]!=str(id)]\n",
    "    book_recs = similar_users.groupby(\"book_id\").ratings.agg(['count', 'mean'])\n",
    "    \n",
    "    books_titles = pd.read_json(\"books_titles.json\")\n",
    "    books_titles[\"book_id\"] = books_titles[\"book_id\"].astype(str)\n",
    "    \n",
    "    book_recs = book_recs.merge(books_titles, how=\"inner\", on=\"book_id\")\n",
    "    \n",
    "    book_recs[\"adjusted_count\"] = book_recs[\"count\"] * (book_recs[\"count\"] / book_recs[\"ratings\"])\n",
    "    book_recs[\"score\"] = book_recs[\"mean\"] * book_recs[\"adjusted_count\"]\n",
    "    book_recs = book_recs[~book_recs[\"book_id\"].isin(my_books[\"book_id\"])]\n",
    "    my_books[\"mod_title\"] = my_books[\"title\"].str.replace(\"[^a-zA-Z0-9 ]\", \"\", regex=True).str.lower()\n",
    "    my_books[\"mod_title\"] = my_books[\"mod_title\"].str.replace(\"\\s+\", \" \", regex=True)\n",
    "    book_recs = book_recs[~book_recs[\"mod_title\"].isin(my_books[\"mod_title\"])]\n",
    "    book_recs = book_recs[book_recs[\"mean\"] >=4]\n",
    "    book_recs = book_recs[book_recs[\"count\"]>2]\n",
    "    top_recs = book_recs.sort_values(\"mean\", ascending=False)\n",
    "    top_recs=top_recs[:50]\n",
    "    top_recs.to_csv('top_recs.csv')\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    title=pd.read_json('books_titles.json')\n",
    "\n",
    "    #to make search easier we conver titles into TF-IDF score\n",
    "\n",
    "\n",
    "\n",
    "    vectorizor=TfidfVectorizer()\n",
    "\n",
    "    tfidf=vectorizor.fit_transform(title['mod_title'])\n",
    "\n",
    "    # Query is name of the book\n",
    "    query='SalttotheSea'\n",
    "    \n",
    "    #user id\n",
    "    id=2\n",
    "    \n",
    "    # Gives us top recommendations of the books the user shuold read\n",
    "    collabrative_filtering(id)\n",
    "    \n",
    "    # search for the book_name then use the collabrative filtering result to give personalised search experience\n",
    "    df=search_query(query, vectorizor)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10fbcc9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7e906\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7e906_level0_col0\" class=\"col_heading level0 col0\" >book_id</th>\n",
       "      <th id=\"T_7e906_level0_col1\" class=\"col_heading level0 col1\" >title</th>\n",
       "      <th id=\"T_7e906_level0_col2\" class=\"col_heading level0 col2\" >ratings</th>\n",
       "      <th id=\"T_7e906_level0_col3\" class=\"col_heading level0 col3\" >cover_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7e906_row0_col0\" class=\"data row0 col0\" >3228</td>\n",
       "      <td id=\"T_7e906_row0_col1\" class=\"data row0 col1\" >Salt to the Sea</td>\n",
       "      <td id=\"T_7e906_row0_col2\" class=\"data row0 col2\" >444</td>\n",
       "      <td id=\"T_7e906_row0_col3\" class=\"data row0 col3\" ><img src=\"https://images.gr-assets.com/books/1437084512m/25614492.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7e906_row1_col0\" class=\"data row1 col0\" >3227</td>\n",
       "      <td id=\"T_7e906_row1_col1\" class=\"data row1 col1\" >The Signal and the Noise: Why So Many Predictions Fail - But Some Don't</td>\n",
       "      <td id=\"T_7e906_row1_col2\" class=\"data row1 col2\" >324</td>\n",
       "      <td id=\"T_7e906_row1_col3\" class=\"data row1 col3\" ><img src=\"https://images.gr-assets.com/books/1355058876m/13588394.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7e906_row2_col0\" class=\"data row2 col0\" >10000</td>\n",
       "      <td id=\"T_7e906_row2_col1\" class=\"data row2 col1\" >The First World War</td>\n",
       "      <td id=\"T_7e906_row2_col2\" class=\"data row2 col2\" >111</td>\n",
       "      <td id=\"T_7e906_row2_col3\" class=\"data row2 col3\" ><img src=\"https://images.gr-assets.com/books/1403194704m/8914.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7e906_row3_col0\" class=\"data row3 col0\" >1</td>\n",
       "      <td id=\"T_7e906_row3_col1\" class=\"data row3 col1\" >The Hunger Games</td>\n",
       "      <td id=\"T_7e906_row3_col2\" class=\"data row3 col2\" >22806</td>\n",
       "      <td id=\"T_7e906_row3_col3\" class=\"data row3 col3\" ><img src=\"https://images.gr-assets.com/books/1447303603m/2767052.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7e906_row4_col0\" class=\"data row4 col0\" >258</td>\n",
       "      <td id=\"T_7e906_row4_col1\" class=\"data row4 col1\" >La sombra del viento</td>\n",
       "      <td id=\"T_7e906_row4_col2\" class=\"data row4 col2\" >3531</td>\n",
       "      <td id=\"T_7e906_row4_col3\" class=\"data row4 col3\" ><img src=\"https://images.gr-assets.com/books/1344545047m/1232.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7e906_row5_col0\" class=\"data row5 col0\" >39</td>\n",
       "      <td id=\"T_7e906_row5_col1\" class=\"data row5 col1\" >A Game of Thrones</td>\n",
       "      <td id=\"T_7e906_row5_col2\" class=\"data row5 col2\" >10692</td>\n",
       "      <td id=\"T_7e906_row5_col3\" class=\"data row5 col3\" ><img src=\"https://images.gr-assets.com/books/1436732693m/13496.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7e906_row6_col0\" class=\"data row6 col0\" >384</td>\n",
       "      <td id=\"T_7e906_row6_col1\" class=\"data row6 col1\" >Frostbite</td>\n",
       "      <td id=\"T_7e906_row6_col2\" class=\"data row6 col2\" >2219</td>\n",
       "      <td id=\"T_7e906_row6_col3\" class=\"data row6 col3\" ><img src=\"https://images.gr-assets.com/books/1361098960m/2282133.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_7e906_row7_col0\" class=\"data row7 col0\" >325</td>\n",
       "      <td id=\"T_7e906_row7_col1\" class=\"data row7 col1\" >A Prayer for Owen Meany</td>\n",
       "      <td id=\"T_7e906_row7_col2\" class=\"data row7 col2\" >3868</td>\n",
       "      <td id=\"T_7e906_row7_col3\" class=\"data row7 col3\" ><img src=\"https://images.gr-assets.com/books/1260470010m/4473.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_7e906_row8_col0\" class=\"data row8 col0\" >323</td>\n",
       "      <td id=\"T_7e906_row8_col1\" class=\"data row8 col1\" >Nesnesitelná lehkost bytí</td>\n",
       "      <td id=\"T_7e906_row8_col2\" class=\"data row8 col2\" >3120</td>\n",
       "      <td id=\"T_7e906_row8_col3\" class=\"data row8 col3\" ><img src=\"https://images.gr-assets.com/books/1265401884m/9717.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e906_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_7e906_row9_col0\" class=\"data row9 col0\" >311</td>\n",
       "      <td id=\"T_7e906_row9_col1\" class=\"data row9 col1\" >The Thorn Birds</td>\n",
       "      <td id=\"T_7e906_row9_col2\" class=\"data row9 col2\" >3721</td>\n",
       "      <td id=\"T_7e906_row9_col3\" class=\"data row9 col3\" ><img src=\"https://images.gr-assets.com/books/1391416796m/3412.jpg\" width=50></img></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24057c04a60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57bfa2d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}